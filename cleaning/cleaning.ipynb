{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COM-480 - Data Visualization | OpenFoodFacts database analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_missing(df, label: str) -> float:\n",
    "    \"\"\"\n",
    "    Percentage of missing values for a given label\n",
    "    \"\"\"\n",
    "    return len(df[(df[label].values == '') | (df[label].isnull())]) / len(df)\n",
    "\n",
    "def nth_most_frequent(df: pd.DataFrame, label: str, split=False, n=25):\n",
    "    \"\"\"\n",
    "    nth most frequent values for a given label\n",
    "    \"\"\"\n",
    "    if split: return df[label].str.split(',').explode().value_counts().nlargest(n)\n",
    "    else: return df[label].value_counts().nlargest(n)\n",
    "\n",
    "def kth_most_frequent_non_cleaned(df, cleaned_label, origin_label, n=25) -> list[str]:\n",
    "    return df.loc[((df[cleaned_label] == '') | (df[cleaned_label].isnull())) & (df[origin_label].notnull()), [origin_label]].value_counts().nlargest(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/8nv4kg9x2zldk0jghwxdl49r0000gn/T/ipykernel_47051/1252387409.py:17: DtypeWarning: Columns (0,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(FILENAME)\n"
     ]
    }
   ],
   "source": [
    "FILENAME = '../datasets/products_0.995.csv'\n",
    "ALLERGENS_TAGS_FILENAME  = 'tags/allergens.json'\n",
    "COUNTRIES_TAGS_FILENAME  = 'tags/countries.json'\n",
    "COUNTRIES_CODES_FILENAME = 'tags/countries_codes.json'\n",
    "PACKAGING_TAGS_FILENAME  = 'tags/packaging.json'\n",
    "\n",
    "with open(COUNTRIES_TAGS_FILENAME, 'r')  as tags_file: COUNTRIES_TAGS  = json.load(tags_file)\n",
    "with open(COUNTRIES_CODES_FILENAME, 'r') as tags_file: COUNTRIES_CODES = json.load(tags_file)\n",
    "with open(ALLERGENS_TAGS_FILENAME, 'r')  as tags_file: ALLERGENS_TAGS  = json.load(tags_file)\n",
    "with open(PACKAGING_TAGS_FILENAME, 'r')  as tags_file: PACKAGING_TAGS  = json.load(tags_file)\n",
    "\n",
    "REGEX_PACKAGING = r'\\b(?:en:|fr:|es:|it:)?([A-Za-zÀ-ÖØ-öø-ÿ\\-\\.0-9]+(?: [A-Za-zÀ-ÖØ-öø-ÿ\\-\\.0-9]+)*)'\n",
    "REGEX_CATEGORY  = r'\\b(?:en:)+([A-Za-zÀ-ÖØ-öø-ÿ\\-\\.0-9]+(?: [A-Za-zÀ-ÖØ-öø-ÿ\\-\\.0-9]+)*)'\n",
    "REGEX_LOCATION  = r'\\b(?:en:|fr:|es:|it:)?([A-Za-zÀ-ÖØ-öø-ÿ\\-\\.0-9]+(?: [A-Za-zÀ-ÖØ-öø-ÿ\\-\\.0-9]+)*)'\n",
    "REGEX_ALLERGEN  = r'\\b(?:en:|fr:|es:|it:)?([A-Za-zÀ-ÖØ-öø-ÿ\\-\\.0-9]+(?: [A-Za-zÀ-ÖØ-öø-ÿ\\-\\.0-9]+)*)'\n",
    "\n",
    "df = pd.read_csv(FILENAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of field `abbreviated_product_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['abbreviated_product_name'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `packaging`, `packaging_tags` and `packaging_en`\n",
    "Material and packaging type of the product\n",
    "\n",
    "The current functions only extract the material (e.g. plastic, metal, ...). \n",
    "\n",
    "We could further analyze those fields to analyze packaging type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_packaging(packaging: str) -> list[str]:\n",
    "    if type(packaging) != str: return []\n",
    "    return re.findall(REGEX_PACKAGING, packaging)\n",
    "\n",
    "def packaging_to_material(packaging: str) -> str:\n",
    "    for material, filters in PACKAGING_TAGS.items():\n",
    "        if material in packaging: return material\n",
    "        if any([f in packaging for f in filters]): return material\n",
    "    return None\n",
    "\n",
    "def cleaning_packaging_material(packaging_tags: str) -> str:\n",
    "    packagings = set(map(packaging_to_material, split_packaging(packaging_tags)))\n",
    "    return ','.join(filter(lambda p: p, packagings))\n",
    "\n",
    "df['packaging'] = df.apply(lambda r : cleaning_packaging_material(r['packaging_tags']), axis=1)\n",
    "df.drop(['packaging_tags', 'packaging_en', 'packaging_text'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `brands` and `brands_tags`\n",
    "Information about the product's brand.\n",
    "\n",
    "Since `brands_tags` is just a formatted version if `brands` and does not add any information we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['brands_tags'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `categories`, `categories_tags` and `categories_en`\n",
    "Food categories of the product (e.g. beverages, meats, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_categories_tag(categories_tags: str) -> str:\n",
    "    if type(categories_tags) != str: return\n",
    "    categories = re.findall(REGEX_CATEGORY, categories_tags)\n",
    "    categories = [category.replace('-', ' ') for category in categories]\n",
    "    return ','.join(categories)\n",
    "\n",
    "df['categories'] = df.apply(lambda r : cleaning_categories_tag(r['categories_tags']), axis=1)\n",
    "df.drop(['categories_tags', 'categories_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `origins`, `origins_tags` and `origins_en`\n",
    "Countries of origin of the ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_locations(locations: str) -> list[str]:\n",
    "    if type(locations) != str: return []\n",
    "    return re.findall(REGEX_LOCATION, locations)\n",
    "\n",
    "def location_to_country(location: str) -> str:\n",
    "    if location in COUNTRIES_TAGS.keys(): return location\n",
    "    if location in COUNTRIES_CODES: return COUNTRIES_CODES[location]\n",
    "    for country, filters in COUNTRIES_TAGS.items():\n",
    "        if country in location: return country\n",
    "        if any([f in location for f in filters]): return country\n",
    "    return None\n",
    "\n",
    "def cleaning_origins(origins: str, origins_tags: str, origins_en: str) -> str:\n",
    "    countries = set(map(location_to_country, split_locations(origins))) \\\n",
    "        | set(map(location_to_country, split_locations(origins_tags))) \\\n",
    "        | set(map(location_to_country, split_locations(origins_en)))\n",
    "    return ','.join(filter(lambda c: c, countries))\n",
    "\n",
    "df['countries_ingredients'] = df.apply(lambda r : cleaning_origins(r['origins'], r['origins_tags'], r['origins_en']), axis=1)\n",
    "df.drop(['origins', 'origins_tags', 'origins_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `manufacturing_places` and `manufacturing_places_tags`\n",
    "Countries where the product is manufactured (e.g. processing, packaging, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_manufacturing(manufacturing_places: str, manufacturing_places_tags: str) -> str:\n",
    "    countries = set(map(location_to_country, split_locations(manufacturing_places))) \\\n",
    "        | set(map(location_to_country, split_locations(manufacturing_places_tags)))\n",
    "    return ','.join(filter(lambda c: c, countries))\n",
    "\n",
    "df['countries_manufacturing'] = df.apply(lambda r : cleaning_manufacturing(r['manufacturing_places'], r['manufacturing_places_tags']), axis=1)\n",
    "df.drop(['manufacturing_places', 'manufacturing_places_tags'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `labels`, `labels_tags` and `labels_en`\n",
    "Labels of the product.\n",
    "\n",
    "Quite hard to extract meaningful information, there is a lot of different labels for each product (by country, food category, ...). I just extracted some information here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_vegan']      = df['labels_tags'].str.contains('vegan', na=False).astype(int)\n",
    "df['is_vegetarian'] = df['labels_tags'].str.contains('vegetarian', na=False).astype(int)\n",
    "df['is_organic']    = df['labels_tags'].str.contains('organic|bio|biologique', na=False).astype(int)\n",
    "df['is_halal']      = df['labels_tags'].str.contains('halal', na=False).astype(int)\n",
    "df['is_kosher']     = df['labels_tags'].str.contains('kosher', na=False).astype(int)\n",
    "\n",
    "df.drop(['labels', 'labels_tags', 'labels_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `emb_codes`, `emb_codes_tags` and `first_packaging_code_geo`\n",
    "EMB Code of the product packaging\n",
    "\n",
    "The field `emb_codes_tags` is just a formatted version of `emb_codes` so we only keep one. The field `first_packaging_code_geo` is almost always null, so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emb_codes'] = df['emb_codes_tags']\n",
    "df.drop(['first_packaging_code_geo', 'emb_codes_tags'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `cities` and `cities_tags`\n",
    "Field `cities` is always empty, we drop it\n",
    "\n",
    "Field `cities_tags` seems hard to exploit (lot of various format), we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['cities', 'cities_tags'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of field `purchase_places`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_purchase_places(purchase_places: str) -> str:\n",
    "    countries = set(map(location_to_country, split_locations(purchase_places)))\n",
    "    return ','.join(filter(lambda c: c, countries))\n",
    "\n",
    "df['purchase_places'] = df.apply(lambda r : cleaning_purchase_places(r['purchase_places']), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `countries`, `countries_tags` and `countries_en`\n",
    "Countries where the product is sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_countries(countries: str, countries_tags: str, countries_en: str) -> str:\n",
    "    countries = set(map(location_to_country, split_locations(countries))) \\\n",
    "        | set(map(location_to_country, split_locations(countries_tags))) \\\n",
    "        | set(map(location_to_country, split_locations(countries_en)))\n",
    "    return ','.join(filter(lambda c: c, countries))\n",
    "\n",
    "df['countries_sold'] = df.apply(lambda r : cleaning_countries(r['countries'], r['countries_tags'], r['countries_en']), axis=1)\n",
    "df.drop(['countries', 'countries_tags', 'countries_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of field `ingredients_analysis_tags`\n",
    "Creation of new fields using tags\n",
    "- `0` : No\n",
    "- `1` : Unknown\n",
    "- `2` : Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_palm_oil(ingredients_analysis_tags: str) -> int:\n",
    "    if type(ingredients_analysis_tags) != str: return 1\n",
    "    if 'en:palm-oil-free' in ingredients_analysis_tags: return 0\n",
    "    if 'en:palm-oil-content-unknown' in ingredients_analysis_tags \\\n",
    "        or 'en:may-contain-palm-oil' in ingredients_analysis_tags: return 1\n",
    "    if 'en:palm-oil' in ingredients_analysis_tags: return 2\n",
    "    else: return 1\n",
    "\n",
    "def cleaning_vegetarian(ingredients_analysis_tags: str) -> int:\n",
    "    if type(ingredients_analysis_tags) != str: return 1\n",
    "    if 'en:non-vegetarian' in ingredients_analysis_tags: return 0\n",
    "    if 'en:vegetarian-status-unknown' in ingredients_analysis_tags \\\n",
    "        or 'en:maybe-vegetarian' in ingredients_analysis_tags: return 1\n",
    "    if 'en:vegetarian' in ingredients_analysis_tags: return 2\n",
    "    else: return 1\n",
    "\n",
    "def cleaning_vegan(ingredients_analysis_tags: str) -> int:\n",
    "    if type(ingredients_analysis_tags) != str: return 1\n",
    "    if 'en:non-vegan' in ingredients_analysis_tags: return 0\n",
    "    if 'en:vegan-status-unknown' in ingredients_analysis_tags \\\n",
    "        or 'en:maybe-vegan' in ingredients_analysis_tags: return 1\n",
    "    if 'en:vegan' in ingredients_analysis_tags: return 2\n",
    "    else: return 1\n",
    "    \n",
    "df['palm_oil'] = df.apply(lambda r : cleaning_palm_oil(r['ingredients_analysis_tags']), axis=1).astype(int)\n",
    "df['is_vegetarian_alt'] = df.apply(lambda r : cleaning_vegetarian(r['ingredients_analysis_tags']), axis=1).astype(int)\n",
    "df['is_vegan_alt'] = df.apply(lambda r : cleaning_vegan(r['ingredients_analysis_tags']), axis=1).astype(int)\n",
    "\n",
    "df.drop(['ingredients_analysis_tags'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of field `allergens`\n",
    "Allergens contained in the product (e.g. milk, fish, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_allergens(allergens: str) -> list[str]:\n",
    "    if type(allergens) != str: return []\n",
    "    return re.findall(REGEX_ALLERGEN, allergens)\n",
    "\n",
    "def tag_to_allergen(tag: str) -> str:\n",
    "    if tag in ALLERGENS_TAGS: return tag\n",
    "    for allergen, filters in ALLERGENS_TAGS.items():\n",
    "        if allergen in tag: return allergen\n",
    "        if any([f in tag for f in filters]): return allergen\n",
    "    return None\n",
    "\n",
    "def cleaning_allergens(allergens: str) -> str:\n",
    "    allergens = set(map(tag_to_allergen, split_allergens(allergens)))\n",
    "    return ','.join(filter(lambda a: a, allergens))\n",
    "\n",
    "df['allergens'] = df.apply(lambda r : cleaning_allergens(r['allergens']), axis=1)\n",
    "df.drop(['allergens_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `traces`, `traces_tags` and `traces_en`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_traces_tags(traces_tags: str) -> str:\n",
    "    if type(traces_tags) != str: return\n",
    "    TRACES = {\n",
    "        'bones': ['arete', 'os'],\n",
    "        'oats': ['avena'],\n",
    "        'phenylalanine': []\n",
    "    }\n",
    "    traces = []\n",
    "    for trace in traces_tags.split(','):\n",
    "        if 'en:' in trace: traces.append(trace.replace('en:', ''))\n",
    "        else:\n",
    "            for t, filters in TRACES.items():\n",
    "                if t in trace or any([f in trace for f in filters]):\n",
    "                    traces.append(t)\n",
    "                    break\n",
    "    return ','.join(traces)\n",
    "\n",
    "df['traces'] = df.apply(lambda r : cleaning_traces_tags(r['traces_tags']), axis=1)\n",
    "df.drop(['traces_tags', 'traces_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of field `no_nutrition_data`\n",
    "Still don't understand the purpose of this field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['no_nutrition_data'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `additives`, `additives_tags`, `additives_n` and `additives_en`\n",
    "Additives present in the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['additives'] = df['additives_en']\n",
    "df.drop(['additives_n', 'additives_tags', 'additives_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `nutriscore_score` and `nutriscore_grade`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_nutriscore_grade(nutriscore_grade: str) -> str:\n",
    "    if type(nutriscore_grade) != str: return None\n",
    "    else: return nutriscore_grade.upper()\n",
    "\n",
    "df['nutriscore_fr'] = df.apply(lambda row : cleaning_nutriscore_grade(row['nutriscore_grade']), axis=1)\n",
    "df.drop(['nutriscore_score', 'nutriscore_grade'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `pnns_groups_1` and `pnns_groups_2`\n",
    "Those fields are deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['pnns_groups_1', 'pnns_groups_2'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `food_groups`, `food_groups_tags` and `food_groups_en`\n",
    "Food groups of the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_food_groups_tags(food_groups_tags: str) -> str:\n",
    "    if type(food_groups_tags) != str: return\n",
    "    return ','.join([group.replace('en:', '') for group in food_groups_tags.split(',')])\n",
    "\n",
    "df['food_groups'] = df.apply(lambda r : cleaning_food_groups_tags(r['food_groups_tags']), axis=1)\n",
    "df.drop(['food_groups_tags', 'food_groups_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of field `brand_owner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['brand_owner'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `ecoscore_score` and `ecoscore_grade`\n",
    "We have to keep both fields since the grade is computed from the score **plus** some other factors that are not easy to extract (packaging, labels, ...). \n",
    "\n",
    "More information : https://docs.score-environnemental.com/v/en/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ecoscore_grade'] = df['ecoscore_grade'].replace(['unknown', 'not-applicable'], None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of field `nutrient_levels_tags`\n",
    "Creation of new fields based on tags :\n",
    "- `0` : Low\n",
    "- `1` : Moderate\n",
    "- `2` : High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_quantity(nutrient_levels_tags: str, tag: str) -> int:\n",
    "    if type(nutrient_levels_tags) != str: return -1\n",
    "    elif f'{tag}-in-low-quantity' in nutrient_levels_tags: return 0\n",
    "    elif f'{tag}-in-moderate-quantity' in nutrient_levels_tags: return 1\n",
    "    elif f'{tag}-in-high-quantity' in nutrient_levels_tags: return 2 \n",
    "    else: return 3\n",
    "\n",
    "df['sugars_quantity'] = df.apply(lambda r : cleaning_quantity(r['nutrient_levels_tags'], 'sugars'), axis=1)\n",
    "df['fat_quantity'] = df.apply(lambda r : cleaning_quantity(r['nutrient_levels_tags'], 'fat'), axis=1)\n",
    "df['saturated_fat_quantity'] = df.apply(lambda r : cleaning_quantity(r['nutrient_levels_tags'], 'saturated_fat'), axis=1)\n",
    "df['salt_quantity'] = df.apply(lambda r : cleaning_quantity(r['nutrient_levels_tags'], 'salt'), axis=1)\n",
    "df.drop(['nutrient_levels_tags'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `owner`, `data_quality_errors_tags` and `popularity_tags`\n",
    "The popularity tags may be useful, but they seems hard to exploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['owner', 'data_quality_errors_tags', 'popularity_tags'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `main_category` and `main_categories_en`\n",
    "Main food category of the product. \n",
    "\n",
    "Fields `main_category` and `main_category_en` have a fuzzy meaning, dropping them and using the first category computed before as the main category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['main_category'] = df['categories'].str.split(',').str[0]\n",
    "df.drop(['main_category_en'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `image_url`, `image_ingredients_url` and `image_nutrition_url`\n",
    "Remove the prefix `https://images.openfoodfacts.org/images/products/` to reduce size of the dataset, we can just add it later if we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_url'] = df['image_url'].str.replace('https://images.openfoodfacts.org/images/products/','', regex=False)\n",
    "df['image_ingredients_url'] = df['image_ingredients_url'].str.replace('https://images.openfoodfacts.org/images/products/','', regex=False)\n",
    "df['image_nutrition_url'] = df['image_nutrition_url'].str.replace('https://images.openfoodfacts.org/images/products/','', regex=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of fields `energy_100g` and `nutrition-score-fr_100g`\n",
    "Those fields are deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['energy_100g', 'nutrition-score-fr_100g'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding field `completeness_custom`\n",
    "New measure of completness of row after cleaning. It's normal to have a low index because of the fields about nutriments (protein, carbs, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_completeness(completeness: float): \n",
    "    return df[df['completeness_custom'] > completeness]\n",
    "\n",
    "def completeness(row) -> float:\n",
    "    completeness = 0.0\n",
    "    for r in row:\n",
    "        if pd.isnull(r) or (type(r) == str and r == ''): completeness += 1.0\n",
    "    return 1 - completeness / len(row)\n",
    "\n",
    "df['completeness_custom'] = df.apply(lambda x: completeness(x), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(FILENAME.replace('.csv', '_cleaned.csv'), index=False)\n",
    "df.head(10).to_csv(FILENAME.replace('.csv', '_cleaned_preview.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
