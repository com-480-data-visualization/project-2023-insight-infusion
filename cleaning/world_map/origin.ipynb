{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data used for the interactive map\n",
    "Cleaning the openfoodfacts dataset as well as calculating scores for manufactuing and raw resources for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '../..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns we're interested in\n",
    "usecols = ['origins', 'manufacturing_places', 'countries']\n",
    "\n",
    "# Specify the data types for these columns\n",
    "dtypes = {col: str for col in usecols}\n",
    "\n",
    "# Load the data, entire openfoodfacts dataset\n",
    "df_raw = pd.read_csv(f'{ROOT_PATH}/datasets/openfoodfacts.csv', delimiter='\\t', usecols=usecols, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_name(country_code):\n",
    "    \"\"\"Convert country code to country name using pycountry library\"\"\"\n",
    "    try:\n",
    "        country_code = country_code[2:] #remove the 'en:' prefix\n",
    "        return pycountry.countries.get(alpha_2=country_code).name\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "def clean_country_names(country, not_found_dict):\n",
    "    \"\"\"Clean the country name fields\"\"\"\n",
    "    if pd.isnull(country):\n",
    "        return None\n",
    "\n",
    "    country = country.strip().lower()\n",
    "        \n",
    "    countries_found = []\n",
    "    \n",
    "    other_accepted = ['bolivia', 'brasil', 'vietnam', 'czech republic']\n",
    "    \n",
    "    # Split the string into words and check each word\n",
    "    for word in country.split(','):\n",
    "        # Check if word is a country code\n",
    "        country_name_from_code = country_name(word)\n",
    "        if country_name_from_code is not None:\n",
    "            countries_found.append(country_name_from_code)\n",
    "        # Check if word is a country name\n",
    "        elif pycountry.countries.get(name=word.capitalize()) is not None:\n",
    "            countries_found.append(word.capitalize())\n",
    "            \n",
    "        elif word.lower() in other_accepted:\n",
    "            countries_found.append(word.capitalize())\n",
    "            \n",
    "        # not found\n",
    "        else:\n",
    "            not_found_dict[word] = not_found_dict.get(word, 0) + 1\n",
    "\n",
    "    # assums first country is the main country\n",
    "    if len(countries_found) != 0:\n",
    "        return countries_found[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "def clean_country_field(field, not_found_dict):\n",
    "    if pd.isnull(field):\n",
    "        return None\n",
    "    \n",
    "    # Split on comma\n",
    "    parts = field.split(',')\n",
    "    \n",
    "    # Clean each part separately\n",
    "    cleaned_parts = [clean_country_names(part.strip(), not_found_dict) for part in parts]\n",
    "    \n",
    "    # Remove None parts\n",
    "    cleaned_parts = [part for part in cleaned_parts if part is not None]\n",
    "    \n",
    "    # Join cleaned parts back together with comma\n",
    "    cleaned_field = ', '.join(cleaned_parts)\n",
    "    \n",
    "    return cleaned_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = {\n",
    "    'turkey': ['turquie'],\n",
    "    'thailand': ['thaïlande'],\n",
    "    'united states': ['états-unis', 'en:united states'],\n",
    "    'peru': ['pérou', 'perú'],\n",
    "    'czech republic': ['czech republic', 'česko'],\n",
    "    'poland': ['pologne'],\n",
    "    'algeria': ['algérie'],\n",
    "    'croatia': ['hrvatska'],\n",
    "    'ivory coast': ['ivory coast'],\n",
    "    'germany': ['alemania'],\n",
    "    'united kingdom': ['en:united kingdom'],\n",
    "    'reunion': ['la réunion'],\n",
    "    'netherlands': ['niederlande'],\n",
    "    'spain': ['andalucía', 'comunidad valenciana', 'navarra', 'castilla-la mancha', 'castilla y león'],\n",
    "    'mexico': ['estado de méxico', 'en:mexico', 'mexique'],\n",
    "    'australia': ['en:australia'],\n",
    "    'argentina': ['en:argentina', 'buenos aires', 'argentine'],\n",
    "    'romania': ['en:romania'],\n",
    "    'denmark': ['danmark'],\n",
    "    'brazil': ['brésil'],\n",
    "    'austria': ['en:austria'],\n",
    "    'ireland': ['irlande'],\n",
    "    'taiwan': ['taiwan'],\n",
    "    'france': ['polynésie française'],\n",
    "    'japan': ['japon'],\n",
    "}\n",
    "\n",
    "map2 = {\n",
    "    'france': ['france', 'en:fr', 'en:france', 'france,europe','belgique,france', 'bretagne', 'bretagne', 'francia', 'frankreich', 'fr', 'normandie', 'pays de la loire', 'vendée', 'provence', 'french', 'paris', 'francais', 'francaise', 'parisien', 'parisienne', 'french republic', 'finistère'],\n",
    "    'spain': ['españa','en:es', 'en:spain','espagne','spain', 'españa', 'espagne', 'españa', 'spanien'],\n",
    "    'germany': ['deutschland','germany','allemagne','en:de', 'deutschland', 'deutschland', 'en:germany'],\n",
    "    'united kingdom': ['en:uk','united kingdom','en:gb','uk','uk', 'royaume-uni'],\n",
    "    'belgium': ['belgique','en:be','belgique,france','belgium','belgique,france', 'belgique'],\n",
    "    'italy': ['italia','en:it', 'en:italy','italie', 'italien', 'italia', 'italie', 'conserve italia s.p.a.'],\n",
    "    'switzerland': ['suisse','switzerland', 'suisse', 'schweiz', 'en:switzerland'],\n",
    "    'netherlands': ['netherlands', 'holland', 'pays-bas', 'nederland'],\n",
    "    'denmark': ['denmark','dänemark'],\n",
    "    'portugal': ['portugal','en:portugal'],\n",
    "    'greece': ['greece','en:gr','grèce','en:greece'],\n",
    "    'sweden': ['sweden','en:se','en:sweden', 'sverige'],\n",
    "    'norway': ['norway','en:no','en:norway'],\n",
    "    'croatia': ['croatia','en:hr','en:croatia'],\n",
    "    'albania': ['albania','en:al','en:albania'],\n",
    "    'canada': ['canada','en:ca','en:canada', 'québec', 'brossard québec'],\n",
    "    'mexico': ['méxico', 'maxico', 'ciudad de méxico'],\n",
    "    'poland': ['polska', 'polen', 'polska'],\n",
    "    'austria': ['österreich'],\n",
    "    'bolivia': ['bolivia'],\n",
    "    'tunisia': ['tunisie'],\n",
    "    'united states': ['estados unidos', 'united states', 'usa'],\n",
    "    'finland': ['suomi'],\n",
    "    'romania': ['românia'],\n",
    "    'morocco' : ['maroc'],\n",
    "    'Ivory Coast': ['côte d\\'ivoire', \"C\\u00f4te d'ivoire\"],\n",
    "    'Hungary': ['magyarország'],\n",
    "    'China': ['chine'],\n",
    "    'Russian Federation': ['россия', 'russia'],\n",
    "    'Peru': ['perú'],\n",
    "    'Slovakia': ['slovensko'],\n",
    "    'czech republic': ['česká republika'],\n",
    "}\n",
    "\n",
    "for k,v in map1.items():\n",
    "    if k in map2:\n",
    "        map1[k] = map2[k] + v\n",
    "        \n",
    "for k,v in map2.items():\n",
    "    if k not in map1:\n",
    "        map1[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('union européenne', 2841), ('', 630), ('european union', 569), ('alsace', 548), ('eu', 510), ('ue', 503), ('rhône-alpes', 488), ('belgien', 478), ('morbihan', 449), ('en:belgium', 440), ('espanha', 418), ('reunion', 392), ('србија', 384), ('německo', 371), ('savoie', 370), ('centre-val de loire', 354), ('loiret', 353), ('nord-pas-de-calais', 347), ('sarthe', 345), ('loire-atlantique', 342), ('nord', 328), ('quiberon', 323), ('europäische union', 319), ('frankrijk', 310), ('basse-normandie', 309), ('angleterre', 308), ('calvados', 307), ('europe', 306), ('frança', 305), ('ivory coast', 301), ('ille-et-vilaine', 294), ('en:ch', 294), ('formec biffi spa', 293), ('norvège', 278), ('méjannes-lès-alès (30)', 277), ('belgië', 275), ('sud-ouest', 274), ('agricultura ue', 273), ('българия', 272), ('bélgica', 270), ('autriche', 269), ('germania', 268), ('isère', 267), ('francie', 266), ('bourgogne', 264), ('la paz', 262), ('aveyron', 256), ('union européenne et non union européenne', 255), ('cataluña', 251), ('via m. buonarroti  5 - 31032 - casale sul sile (tv) italia', 250), ('non indiqué', 247), ('madi ventura s.p.a.', 247), ('drogheria e alimentari s.p.a.', 246), (\"via dell'industria 14 - 26010 - chieve (cr) italia\", 246), ('lorraine', 245), ('v.le nilde iotti 23/25 - 50038 - scarperia e san piero (fi) italia', 245), ('agricultura no ue', 243), (\"provence-alpes-côte d'azur\", 240), ('niemcy', 237), ('pas-de-calais', 234), ('aquitaine', 233), ('fietta s.p.a.', 232), ('via portile 12 – 36061 – bassano del grappa (vi) italia', 232), ('franche-comté', 231), ('corse', 230), ('hors france', 230), ('cochabamba', 226), ('drôme', 220), ('slovenija', 216), ('scotland', 213), ('auvergne', 213), ('sammontana s.p.a.', 211), ('francja', 209), ('murano s.p.a.', 208), (\"via nazionale delle puglie 287 - 80038 - pomigliano d'arco (na) italia\", 208), ('midi-pyrénées', 206), ('taiwan', 204), ('afrique du sud', 202), ('murcia (comunidad autónoma)', 202), ('danemark', 201), (\"côtes-d'armor\", 201), ('santa cruz', 200), ('hamburg', 199), ('schleswig-holstein', 198), ('irland', 197), ('ελλάδα', 197), ('griechenland', 196), ('en:russia', 196), ('vaucluse', 194), ('vicenzi s.p.a.', 194), ('en:poland', 191), ('suède', 190), ('valencia (provincia)', 189), ('mainardi nicola s.r.l.', 189), ('via porte di sopra 59 - 45026 - lendinara (ro)', 189), ('bayern', 187), ('madrid', 187), ('murcia', 187), ('australie', 186), ('picardie', 186)]\n",
      "180215\n"
     ]
    }
   ],
   "source": [
    "df = df_raw.dropna(subset=['countries', 'manufacturing_places'], how='any')\n",
    "\n",
    "# Convert the country names to a standard format\n",
    "df = df.applymap(lambda s: s.strip().lower() if isinstance(s, str) else s)\n",
    "\n",
    "\n",
    "def apply_alias_mapping(alias_mapping, s):\n",
    "    if isinstance(s, str):\n",
    "        # Split the string into individual values\n",
    "        values = s.split(',')\n",
    "        # Apply the mapping to each value\n",
    "        mapped_values = [alias_mapping.get(\n",
    "            value.strip().lower(), value) for value in values]\n",
    "        # Join the mapped values back together\n",
    "        return ','.join(mapped_values)\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "\n",
    "# Define a mapping from country aliases to the standard country name\n",
    "# Note: All country names and aliases are now in lowercase\n",
    "country_mapping = map1\n",
    "\n",
    "# Flatten the mapping to make it easy to apply\n",
    "alias_mapping = {alias.lower(): country for country,\n",
    "                 aliases in country_mapping.items() for alias in aliases}\n",
    "\n",
    "# Apply the mapping to each column\n",
    "df = df.applymap(lambda x: apply_alias_mapping(alias_mapping, x))\n",
    "\n",
    "\n",
    "# Clean the origin fields\n",
    "not_found_dict = {}\n",
    "df['origins'] = df['origins'].apply(\n",
    "    lambda x: clean_country_field(x, not_found_dict))\n",
    "df['manufacturing_places'] = df['manufacturing_places'].apply(\n",
    "    lambda x: clean_country_field(x, not_found_dict))\n",
    "df['countries'] = df['countries'].apply(\n",
    "    lambda x: clean_country_field(x, not_found_dict))\n",
    "\n",
    "# Drop the rows where at least one element is missing.\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "# post remapping\n",
    "country_mapping_post = {\n",
    "    'Usa': ['united states'],\n",
    "    'England': ['united kingdom'],\n",
    "    'Russia': ['russian federation'],\n",
    "    'Brazil': ['brasil']\n",
    "}\n",
    "alias_mapping_post = {alias.lower(): country for country,\n",
    "                 aliases in country_mapping_post.items() for alias in aliases}\n",
    "df = df.applymap(lambda x: apply_alias_mapping(alias_mapping_post, x))\n",
    "\n",
    "# sort not_found_dict by value and print out top 10 not found words\n",
    "sorted_not_found_dict = sorted(\n",
    "    not_found_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(sorted_not_found_dict[:100])\n",
    "total_misses = 0\n",
    "for v in sorted_not_found_dict:\n",
    "    total_misses += v[1]\n",
    "print(total_misses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origins</th>\n",
       "      <th>manufacturing_places</th>\n",
       "      <th>countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48027</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505576</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728337</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824135</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151164</th>\n",
       "      <td>Perú</td>\n",
       "      <td>Perú</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178104</th>\n",
       "      <td>Lima,Peru</td>\n",
       "      <td>Lima,Peru</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206985</th>\n",
       "      <td>Perú</td>\n",
       "      <td>Lima,Perú</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222230</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222584</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225534</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225578</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225620</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225623</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225686</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225723</th>\n",
       "      <td>Peru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225749</th>\n",
       "      <td>Perú</td>\n",
       "      <td>peru</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225827</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225893</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225906</th>\n",
       "      <td>Perú</td>\n",
       "      <td>Perú</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pérou</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226029</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226089</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226150</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226229</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Perú</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226256</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226316</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226587</th>\n",
       "      <td>Chocolate from Peru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226612</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226720</th>\n",
       "      <td>Peru</td>\n",
       "      <td>Lima</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226880</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227055</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227056</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237263</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240984</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515368</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Terrer España</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583587</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Barcelona españa</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     origins manufacturing_places countries\n",
       "48027                    NaN                  NaN      Peru\n",
       "505576                   NaN                  NaN      Peru\n",
       "611199                   NaN                  NaN      Peru\n",
       "728337                   NaN                  NaN      Peru\n",
       "824135                   NaN                  NaN      Peru\n",
       "2151164                 Perú                 Perú      Peru\n",
       "2178104            Lima,Peru            Lima,Peru      Peru\n",
       "2206985                 Perú            Lima,Perú      Peru\n",
       "2222230                  NaN                  NaN      Peru\n",
       "2222584                  NaN                  NaN      Peru\n",
       "2225534                  NaN                  NaN      Peru\n",
       "2225578                  NaN                  NaN      Peru\n",
       "2225620                  NaN                  NaN      Peru\n",
       "2225623                  NaN                  NaN      Peru\n",
       "2225686                  NaN                  NaN      Peru\n",
       "2225723                 Peru                  NaN      Peru\n",
       "2225749                 Perú                 peru      Peru\n",
       "2225827                  NaN                  NaN      Peru\n",
       "2225893                  NaN                  NaN      Peru\n",
       "2225906                 Perú                 Perú      Peru\n",
       "2226003                  NaN                Pérou      Peru\n",
       "2226012                  NaN                  NaN      Peru\n",
       "2226018                  NaN                  NaN      Peru\n",
       "2226029                  NaN                  NaN      Peru\n",
       "2226089                  NaN                  NaN      Peru\n",
       "2226150                  NaN                  NaN      Peru\n",
       "2226229                  NaN                  NaN      Peru\n",
       "2226243                  NaN                  NaN      Peru\n",
       "2226244                  NaN                 Perú      Peru\n",
       "2226256                  NaN                  NaN      Peru\n",
       "2226316                  NaN                  NaN      Peru\n",
       "2226587  Chocolate from Peru                  NaN      Peru\n",
       "2226612                  NaN                 Peru      Peru\n",
       "2226720                 Peru                 Lima      Peru\n",
       "2226880                  NaN                  NaN      Peru\n",
       "2227055                  NaN                  NaN      Peru\n",
       "2227056                  NaN                  NaN      Peru\n",
       "2237263                  NaN                  NaN      Peru\n",
       "2240984                  NaN                  NaN      Peru\n",
       "2492911                  NaN                  NaN      Peru\n",
       "2515368                  NaN        Terrer España      Peru\n",
       "2583587                  NaN     Barcelona españa      Peru"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw[df_raw['countries'] == 'Peru']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output format:\n",
    "[\n",
    "  {\n",
    "    \"bolivia\": {\n",
    "      \"score\": 0.2,\n",
    "      \"manufacturing\": {\n",
    "        \"France\": {\n",
    "          \"score\": 0.2,\n",
    "          \"origin\" {\n",
    "            \"Norway\": 0.1\n",
    "          }\n",
    "        },\n",
    "        \"Germany\": 0.12,\n",
    "      }\n",
    "    },\n",
    "    \"\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coutry_count = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  cosumptions = row['countries']\n",
    "  origins = row['origins']\n",
    "  manufacturings = row['manufacturing_places']\n",
    "  \n",
    "  for cosumption in cosumptions.split(','):\n",
    "    cosumption = cosumption.strip()\n",
    "    \n",
    "    if cosumption == \"\":\n",
    "      continue\n",
    "    \n",
    "    if cosumption not in coutry_count:\n",
    "      coutry_count[cosumption] = {}\n",
    "      coutry_count[cosumption][\"score\"] = 1\n",
    "      coutry_count[cosumption][\"manufacturing\"] = {}\n",
    "    else:\n",
    "      coutry_count[cosumption][\"score\"] += 1\n",
    "      \n",
    "    for manufacturing in manufacturings.split(','):\n",
    "      manufacturing = manufacturing.strip()\n",
    "      \n",
    "      if manufacturing == \"\":\n",
    "        continue\n",
    "        \n",
    "      if manufacturing not in coutry_count[cosumption][\"manufacturing\"]:\n",
    "        coutry_count[cosumption][\"manufacturing\"][manufacturing] = {}\n",
    "        coutry_count[cosumption][\"manufacturing\"][manufacturing][\"score\"] = 1\n",
    "        coutry_count[cosumption][\"manufacturing\"][manufacturing][\"origin\"] = {}\n",
    "      else:\n",
    "        coutry_count[cosumption][\"manufacturing\"][manufacturing][\"score\"] += 1\n",
    "        \n",
    "      for origin in origins.split(','):\n",
    "        origin = origin.strip()\n",
    "        if origin == \"\":\n",
    "          continue\n",
    "        \n",
    "        if origin not in coutry_count[cosumption][\"manufacturing\"][manufacturing][\"origin\"]:\n",
    "          coutry_count[cosumption][\"manufacturing\"][manufacturing][\"origin\"][origin] = 1\n",
    "        else:\n",
    "          coutry_count[cosumption][\"manufacturing\"][manufacturing][\"origin\"][origin] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize value\n",
    "consume_score = 0\n",
    "\n",
    "for consume in coutry_count.values():\n",
    "  consume_score += consume[\"score\"]\n",
    "  \n",
    "  manufacture_score = 0\n",
    "  for manufacturing in consume[\"manufacturing\"].values():\n",
    "    manufacture_score += manufacturing[\"score\"]\n",
    "    \n",
    "    origin_score = 0\n",
    "    for origin in manufacturing[\"origin\"].values():\n",
    "      origin_score += origin\n",
    "    for k, origin in manufacturing[\"origin\"].items():\n",
    "      manufacturing[\"origin\"][k] /= origin_score\n",
    "  \n",
    "  for manufacturing in consume[\"manufacturing\"].values():\n",
    "    manufacturing[\"score\"] /= manufacture_score\n",
    "    \n",
    "for consume in coutry_count.values():\n",
    "  consume[\"score\"] /= consume_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove country if score is less than 0.01\n",
    "th = 0.01\n",
    "\n",
    "for ck in list(coutry_count.keys()):\n",
    "    consume = coutry_count[ck]\n",
    "    \n",
    "    for mk in list(consume[\"manufacturing\"].keys()):\n",
    "        manufacturing = consume[\"manufacturing\"][mk]\n",
    "        for ok in list(manufacturing[\"origin\"].keys()):\n",
    "            origin = manufacturing[\"origin\"][ok]\n",
    "            if origin < th:\n",
    "                del coutry_count[ck][\"manufacturing\"][mk][\"origin\"][ok]\n",
    "                \n",
    "        if manufacturing[\"score\"] < th or not manufacturing[\"origin\"]:\n",
    "            del coutry_count[ck][\"manufacturing\"][mk]\n",
    "            continue\n",
    "          \n",
    "    if not consume[\"manufacturing\"]:\n",
    "        del coutry_count[ck]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to a JSON file\n",
    "with open(f'./country_count.json', 'w') as f:\n",
    "    json.dump(coutry_count, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
